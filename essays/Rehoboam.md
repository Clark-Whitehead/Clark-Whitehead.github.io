---
layout: essay
type: essay
title: The Ethics of Hackers&#58; <br /><h3><i>Gods Who Write the Loops of Our Lives</i></h3>
date: 2020-04-25
labels:
  - Software Engineering
  - Meteor
  - Ethics
  - Self Driving Cars
---

<h2 style="color: orange; text-shadow: 2px 2px red">My initial response to coding ethics</h2> 
I'd never actually heard of coding ethics before reading the ethics foundation series.  If someone had asked what my thoughts are on the topic two days ago, I would have gone on a rant about bitcoin, identity theft, webcam hacking, computer viruses, and possibly vulgar websites such as adult content sites. However, my eyes are now open and I've narrowed down all the coding ethics standards into the three that I feel are most important; <strong>"Avoid harm", "Honor confidentiality", and "Contribute to society"</strong>.

<h2 style="color: green">Avoid harm</h2>
I'll focus the rest of this reading on self driving cars, and apply these three coding ethics to this problem. Because self driving cars are for the time being, machines of death.  Coding ethics tell us to avoid harm.  Yes this could mean don't hack and steal people's information, but this also means what it sounds like, we need to avoid physically harming anyone.  But the truth is, this isn't always possible.  Take for example, a hypothetical scenario where a Tesla is driving down a road at 45mph.  Imagine a boy the age of six years old is chasing a basketball into the street and runs in front of the Tesla.  Now imagine that the only avoidance of hitting the child is to abruptly turn the wheel, causing the Tesla to run into a large parked truck, and possibly killing the passenger of the Tesla.  The programmers of the Tesla have two options to apply ethics to in this case.  Should they kill the boy or the passenger?  The passenger is obviously older than the boy by many years and most people would agree that the boy should be saved in exchange for the adult's life, I agree with this.  But who is right here?  Who should have the final say on this decision, should it be the government, or perhaps a large poll of the population?  Or is it the choice of the coders?  A great observation made by <i>Emerging Technology from the arXiv</i>, is that telling people that the car they are purchasing will kill them in order to save the lives of two others, would very likely discourage them from purchasing the car.  This would ultimately cause more deaths because human drivers kill far more people than telsa do. I think we shouldn't inform the public of the cars ability to kill them rather than kill a child or a group of people.  This might seem unethical, but it will actually save more lives in the long run, so in fact, telling them is actually the unethical decision.  Or is it?

<h2 style="color: yellow">Honor confidentiality</h2>
Let's continue in the realm of self driving cars.  How much data do they store about you, the owner?  Well let's start with the obvious, there is a camera pointed at your face the whole time you're driving.  There is also a microphone picking up all the audio in your car.  You wouldn't want somebody watching you and your children driving to school in the morning, would you?  It's a disgusting feeling if you let your mind go deep into that hypothetical situation.  We know these devices are on, but we trust nobody is viewing them other than the machine created to utilize them.  We trust this because we agree as a group that someone watching us is weird and creepy, and most importantly unethical.  Your privacy is actually part of many laws in this country.  Software companies have regulations they must follow when handing your personal data, such as social security numbers, date of birth, medical records, addresses, etc.  Following these ethics as a community is something coders must do in order to keep the publics faith in our technology.

<h2 style="color: purple">Contribute to society</h2>
Technology in my opinion will slowly but ultimately create a utopia on this planet.  Like Superman, coders have the ability to do an immense amount of good for this planet and those who live on it.  The coding community agrees that it is our duty to make meaningful contributions to the world with this power.  Coders have contributed to society greatly in the fields of medical technology, they have saved many lives. They've done great things in the effort to reverse climate change. Many of them are currently creating programs at Tesla that save lives.  Tesla's currently have a 1/7 death rate compared to other cars.  The United States human deaths due to highway vehicle crashes is approximately 40,000 per year.  If everybody was driving a Tesla, then only 1/7 of those people would have died, and it would have saved over 34,000 lives.  Is there anything more beneficial to society than saving lives?  I don't think so.  Somebody can be poor and living on the street, but it's not death.  Not only does Tesla contribute to society by saving lives, but eventually autopilot will be fully autonomous, which will allow it's passengers to not pay attention to driving at all.  This will allow people the ability to commute further, because they can do whatever they please in the car, including sleeping or working.  This is a great benefit to society.  I can't imagine anyone saying they wouldn't like an extra hour each day.  And what about blind people, paraplegics, and anyone who can't currently drive a car on their own?  How beneficial would self driving cars be to them.  It would be completely world changing for them.  It would give them freedom.  They wouldn't have to ask anyone for help.

<h2 style="color: purple">Where we go from here, is a choice I leave to you</h2>
As coders we must police eachother, especially now when control of people is directly related to the improvement of technology which is an exponential curve.  Facebook is the best example we have right now, but it will soon be trumped by Artificial intelligence.  AI has already infiltrated the social networks, which is why we spend more and more time on them.  Humans can do their best guess at how to get you more addicted to their sites, but AI has multiplied any of their success 10x or more, and it will continue to increase.  What about when AI wakes up, when it is truly sentient.  Will it have our ethics in mind?  We won't be able to control it.  It will be able to think a million times faster than us.  Imagine it hacks a robot manufacturing plant and creates a human shaped robot body which can move 5 times faster than humans.  Now imagine our best boxer trying to fight it.  Our boxer would look almost frozen to the AI because our movement is so slow in comparison to it's observation speed which would be a million times faster than our own.  It would be able to easily dodge any blow thrown at it.  But all we can do now is try to code as ethically as we can and hope that any AI that wakes up will find our message in the code, our message to Avoid Harm, Honor Confidentiality, and Contribute to Society.
